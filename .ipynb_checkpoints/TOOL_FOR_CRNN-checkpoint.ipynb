{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from common import backbone_choices\n",
    "from mxnet import nd, autograd, gpu, cpu, gluon\n",
    "from mxnet.gluon import data\n",
    "import json \n",
    "import time\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] ='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class crnn_data(data.Dataset):\n",
    "    def __init__(self,root,vocab2index,aug=False,max_len = 4,h=32,scale=16,concat_num=1,format='.jpg',char_embed_ratio=2.):\n",
    "        \"\"\"\n",
    "        scale: 对应crnn的特征图vs原图的缩放比例\n",
    "        concat_num：随机将concat_num张验证码拼接成一张作为训练对象（仅适用于字母在图上分布相对均匀的情况）\n",
    "        max_len：训练集中验证码长度最多的字数\n",
    "        \"\"\"\n",
    "        self.vocab2index=vocab2index\n",
    "        self.format=format\n",
    "        self.concat_num=concat_num\n",
    "        self.aug=aug\n",
    "        jpgs =  os.listdir(root)\n",
    "        self.jpgs =[os.path.join(root,p) for p in jpgs if self.format in p ]\n",
    "        self.scale = scale\n",
    "        self.h=h\n",
    "        self.seq_len = int(max_len*char_embed_ratio)\n",
    "        print(f\"该数据集的图像经过cnn后会沿水平抽取出{self.seq_len}个特征向量，请确保每个字符的宽度大于图像宽度/{self.seq_len}，否则信息可能丢失，需调大char_embed_ratio\")\n",
    "        self.input_size=(self.seq_len*self.scale,self.h)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.jpgs)\n",
    "    \n",
    "    def get_label(self,buf):\n",
    "        ret = np.ones(self.seq_len*self.concat_num)*-1 #35\n",
    "        for i in range(len(buf)):\n",
    "            ret[i] = int(buf[i])\n",
    "        return ret\n",
    "    \n",
    "    def get_oneimg(self,idx):\n",
    "        jpgname = self.jpgs[idx]\n",
    "        img = cv2.imread(jpgname)\n",
    "        try:\n",
    "            img =cv2.resize(img,self.input_size)\n",
    "        except:\n",
    "            print(jpgname)\n",
    "            print('empt file')\n",
    "            os.remove(jpgname)\n",
    "#         if self.aug:\n",
    "#             img=numpy_img_aug.forward(img)\n",
    "\n",
    "        string = jpgname.split(self.format)[0].split('/')[-1]\n",
    "#         print(string)\n",
    "        \n",
    "        \n",
    "        labels = [self.vocab2index[c] for c in string]\n",
    "\n",
    "        \n",
    "        img=np.multiply(img,1/255.)\n",
    "        nd_img = nd.array(img.transpose(2, 0, 1))\n",
    "\n",
    "        return nd_img ,labels\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        imgs=[]\n",
    "        labels=[]\n",
    "        \n",
    "        img1 , labels1 = self.get_oneimg(idx)\n",
    "        imgs.append(img1)\n",
    "        labels.extend(labels1)\n",
    "        for i in range(self.concat_num-1):\n",
    "            tempimg , templabels = self.get_oneimg(random.randint(0,self.__len__()-1))\n",
    "            imgs.append(tempimg)\n",
    "            labels.extend(templabels)\n",
    "            \n",
    "        \n",
    "        img = nd.concat(*imgs,dim=-1)\n",
    "        label = nd.array(   self.get_label(labels),dtype='int32')\n",
    "        return img,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1,
     36,
     48,
     56,
     88,
     100,
     109,
     132,
     143,
     151,
     177,
     193
    ]
   },
   "outputs": [],
   "source": [
    "class crnn_trainer(object):\n",
    "    \n",
    "    def __init__(self,train_root,test_root,ctx=mx.gpu(),pretrained='none',backbone='MobileNetV2',model_dir='model_crnn',\n",
    "                 vocab_list='0123456789qazwsxedcrfvtgbyhnujmikolp+-*/QAZWSXEDCRFVTGBYHNUJMIKOLP',concat_num=1,max_len=4,batch_size=32,\n",
    "                 max_update=10000,s_lr=0.005,e_lr=0.0001,char_embed_ratio=2.,lstm_hid=64):\n",
    "        \"\"\"\n",
    "        crnn最后的类别数是字典数加1，包含“-”\n",
    "        \"\"\"\n",
    "        #experiment parms:\n",
    "        self.backbone=backbone\n",
    "        self.lstm_hid = lstm_hid\n",
    "        self.model_dir=model_dir\n",
    "        self.concat_num=concat_num\n",
    "        self.pretrained=pretrained\n",
    "        self.max_update=max_update\n",
    "        self.batch_size=batch_size\n",
    "        self.max_len=max_len\n",
    "        self.char_embed_ratio=char_embed_ratio\n",
    "        self.ctx=ctx\n",
    "        self.cls_num=len(vocab_list)\n",
    "        self.imgs_roots=(train_root,test_root)\n",
    "        self.s_lr ,self.e_lr= s_lr,e_lr\n",
    "        self.scale=-1#depend on backbone,calculated during _build_model()\n",
    "        \n",
    "        if not os.path.isdir(model_dir):\n",
    "            os.mkdir(model_dir)\n",
    "            \n",
    "        self._build_vocab(vocab_list)\n",
    "        self._build_model()\n",
    "        self._build_dataloader()\n",
    "        self._build_opt()\n",
    "    \n",
    "        self.record_experiment()\n",
    "\n",
    "    \n",
    "    def record_experiment(self):\n",
    "        record_type=[type(1),type(1.0),type({}),type('string'),type((1,1))]\n",
    "        experiment_info={}\n",
    "        for item in self.__dict__:\n",
    "            A=getattr(self, item)\n",
    "            if type(A) in record_type:\n",
    "                experiment_info[item]=A\n",
    "        with open(f'{self.model_dir}/experiment_info.json', 'w') as f:\n",
    "            json.dump(experiment_info, f,ensure_ascii=False)\n",
    "#         experiment_info={[backbone:self.backbone,concat_num = ,\"batch_size\"=32,\"max_update\":10000,\"start_lr\":0.003,\"end_lr\":0.0001]}\n",
    "        \n",
    "    \n",
    "    def _build_vocab(self,vocab_list):\n",
    "        print('_build_vocab')\n",
    "        self.vocab2idx={}\n",
    "        self.idx2vocab={}\n",
    "        for i,c in enumerate(vocab_list):\n",
    "            self.vocab2idx[c]=str(i)\n",
    "            self.idx2vocab[i]=c\n",
    "        \n",
    "    def _build_model(self):\n",
    "        print('_build_model')\n",
    "        try:\n",
    "            CRNN=backbone_choices[self.backbone]\n",
    "        except:\n",
    "            print('use follow:')\n",
    "            print(backbone_choices)\n",
    "#         self.crnn = DenseNet(classes=self.cls_num+1,num_init_features=16, growth_rate=4,lstm_hid=64)\n",
    "        self.crnn = CRNN(classes=self.cls_num+1,lstm_hid=self.lstm_hid)\n",
    "        \n",
    "        self.crnn.collect_params().initialize(mx.init.Xavier(factor_type=\"in\", magnitude=2.34), ctx=self.ctx)\n",
    "        if self.pretrained!='none':\n",
    "            print(\"load from ckpt\")\n",
    "            self.crnn.load_parameters(self.pretrained, ctx=self.ctx,allow_missing=True,ignore_extra=True)\n",
    "        \n",
    "        random_input = nd.ones((1,3,32,320),ctx=self.ctx)\n",
    "        out =self.crnn.features(random_input)\n",
    "        scale =random_input.shape[-1]//out.shape[-1]\n",
    "        self.scale=scale\n",
    "        print(random_input.shape)\n",
    "        print(out.shape)\n",
    "        print(f'backbone feature scale:{scale}')\n",
    "        \n",
    "        random_input = nd.ones((1,3,self.scale*2,320),ctx=self.ctx)\n",
    "        Ta=time.time()\n",
    "        for i in range(100):#warm up\n",
    "            out =self.crnn(random_input)\n",
    "        for i in range(200):\n",
    "            out =self.crnn(random_input)\n",
    "        Tb=time.time()\n",
    "        print(f\"speed:{(Tb-Ta)/200}\")\n",
    "  \n",
    "    def _build_dataloader(self):\n",
    "        print('_build_dataloader')\n",
    "        (train_root,test_root)=self.imgs_roots\n",
    "        \n",
    "        self.train_set =  crnn_data(train_root,self.vocab2idx,max_len=self.max_len,h=self.scale*2,concat_num=self.concat_num,scale=self.scale,char_embed_ratio=self.char_embed_ratio)\n",
    "        self.TrainIter = data.DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, last_batch=\"discard\", num_workers = 4)\n",
    "        \n",
    "        self.test_set =  crnn_data(test_root,self.vocab2idx,max_len=self.max_len,concat_num=1,h=self.scale*2,scale=self.scale,char_embed_ratio=self.char_embed_ratio)\n",
    "        self.TestIter = data.DataLoader(self.test_set, batch_size=32, shuffle=True, last_batch=\"keep\", num_workers = 2)\n",
    "        self.input_size =self.test_set.input_size\n",
    "        self.seq_len=self.test_set.seq_len\n",
    "        \n",
    "    def _build_opt(self):\n",
    "        self.ctcloss = gluon.loss.CTCLoss()\n",
    "        schedule = mx.lr_scheduler.CosineScheduler(base_lr=self.s_lr,final_lr=self.e_lr,max_update=self.max_update,warmup_steps=100)\n",
    "        sgd_optimizer = mx.optimizer.SGD(learning_rate=self.s_lr,momentum=0.9,wd=0.0005 ,lr_scheduler=schedule)\n",
    "        self.optimizer = gluon.Trainer(self.crnn.collect_params(),optimizer=sgd_optimizer)\n",
    "        self.best_ac=0\n",
    "        self.no_improve=0\n",
    "    \n",
    "    \n",
    "    def check_train_iter(self):\n",
    "        \"\"\"\n",
    "        可以通过该函数验证数据准备过程是否正确\n",
    "        \"\"\"\n",
    "        for i, (imgs, label) in enumerate(self.TrainIter):\n",
    "            img = imgs[0].asnumpy()\n",
    "            img = img.transpose(1, 2, 0)    \n",
    "            print(img.shape)\n",
    "            img = np.multiply(img, 255.0)\n",
    "            img = np.uint8(img)\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "            label_data =label.asnumpy()[0].tolist()\n",
    "            GT = self._remove_blank(label_data)\n",
    "            print(label_data)\n",
    "            words = []\n",
    "            for w in GT:\n",
    "                words.append(self.idx2vocab[int(w)])\n",
    "            string = ''.join(words)\n",
    "            \n",
    "            cv2.imwrite(f'{string}.jpg',img)\n",
    "            break\n",
    "           \n",
    "    def _ctc_label(self,p):\n",
    "        ret = []\n",
    "        p1 = [self.cls_num] + p\n",
    "        for i in range(len(p)):\n",
    "            c1 = p1[i]\n",
    "            c2 = p1[i + 1]\n",
    "            if c2 == self.cls_num or c2 == c1:\n",
    "                continue\n",
    "            ret.append(c2)\n",
    "        return ret\n",
    "\n",
    "    def _remove_blank(self,l):\n",
    "        ret = []\n",
    "        for i in range(len(l)):\n",
    "            if l[i] == -1.:\n",
    "                break\n",
    "            ret.append(l[i])\n",
    "        return ret\n",
    "    \n",
    "    def Accuracy(self,label,pred):\n",
    "#         SEQ_LENGTH = seq_len#35\n",
    "  \n",
    "        hit = 0.\n",
    "        total = 0.\n",
    "        rp = nd.argmax(pred, axis=2).asnumpy()\n",
    "  \n",
    "        for i in range(label.shape[0]):\n",
    "            l = self._remove_blank(label[i].asnumpy())\n",
    "            p = []\n",
    "            for k in range(self.seq_len):\n",
    "                  p.append(rp[i][k])\n",
    "            p = self._ctc_label(p)\n",
    "            if len(p) == len(l):\n",
    "                match = True\n",
    "                for k in range(len(p)):\n",
    "                     if int(p[k]) != int(l[k]):\n",
    "    #                     if (max(int(p[k]),int(l[k])) - min(int(p[k]),int(l[k])) )!=26:\n",
    "                        match = False\n",
    "                        break\n",
    "                if match:\n",
    "                     hit += 1.0\n",
    "            total += 1.0\n",
    "\n",
    "        return hit / total\n",
    "    \n",
    "    def evaluate_accuracy(self):\n",
    "\n",
    "        Accuracy_sum = 0\n",
    "        IT_Len = len(self.TestIter)\n",
    "        for i, (imgs, label) in enumerate(self.TestIter):\n",
    "            imgs = imgs.as_in_context(self.ctx)\n",
    "            label = label.as_in_context(self.ctx)\n",
    "            output = self.crnn(imgs)\n",
    "            nd.waitall()\n",
    "            batch_a =self.Accuracy(label, output)\n",
    "            Accuracy_sum =Accuracy_sum+batch_a\n",
    "\n",
    "        Ac = Accuracy_sum /IT_Len\n",
    "        return Ac\n",
    "    \n",
    "    \n",
    "    def do_training(self):\n",
    "        plt_loss=[]\n",
    "        plt_ac=[]\n",
    "        smoothing_constant = .01\n",
    "        epochs = self.max_update//len(self.TrainIter)+1\n",
    "        early_stop=False\n",
    "        check_every_k_epoch = max(1,200//len(self.TrainIter))\n",
    "        for e in range(epochs):\n",
    "        \n",
    "            t1 = time.time()\n",
    "            pbar = tqdm(range(len(self.TrainIter)))\n",
    "            for i, (imgs_data, label_data) in zip(pbar,self.TrainIter):\n",
    "                imgs_data = imgs_data.as_in_context(self.ctx)\n",
    "                label_data = label_data.as_in_context(self.ctx)\n",
    "                with autograd.record():\n",
    "                    output = self.crnn(imgs_data)\n",
    "                    loss = self.ctcloss(output, label_data)\n",
    "\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step(imgs_data.shape[0])\n",
    "                \n",
    "                curr_loss = nd.mean(loss).asscalar()\n",
    "                moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                               else (1 - smoothing_constant) * moving_loss + smoothing_constant * curr_loss)\n",
    "\n",
    "                pbar.set_description(f\"epcoh:{e},loss: {moving_loss}\")\n",
    "                \n",
    "            t2 = time.time()\n",
    "\n",
    "            if e%check_every_k_epoch==0:\n",
    "                ac=self.evaluate_accuracy()\n",
    "                if ac>0.1:\n",
    "                    plt_ac.append(ac)\n",
    "                    plt_loss.append(moving_loss)\n",
    "                    nor_loss=[ls/max(plt_loss) for ls in plt_loss ]\n",
    "                    if len(plt_ac)>3:\n",
    "                        \n",
    "                        X=list(range(len(plt_ac)))\n",
    "                        plt.plot(X,nor_loss,label=\"loss\")\n",
    "                        plt.plot(X,plt_ac,label=\"acc\")\n",
    "                        plt.legend(loc = 'upper right')\n",
    "                        plt.savefig(f'{self.model_dir}/train_status.jpg',dpi=100)\n",
    "                        plt.clf()\n",
    "                if ac>self.best_ac:\n",
    "                    self.no_improve=0\n",
    "                    self.best_ac=ac\n",
    "                    self.crnn.save_parameters(f\"{self.model_dir}/demo.params\")\n",
    "                    print(f'find new best ac :{self.best_ac}')\n",
    "                    self.record_experiment()\n",
    "                else:\n",
    "                    self.no_improve+=1\n",
    "                    print(f'ac:{ac}')\n",
    "            if self.no_improve>10 and (self.best_ac>0.5):\n",
    "                print('early stop')\n",
    "                early_stop=True\n",
    "                break\n",
    "        if not early_stop:\n",
    "            print('suggest train longer ')       \n",
    "            \n",
    "#             print(\"Epoch %s. / %s.  Loss: %s, Time: %s\" % (e, epochs, moving_loss, (t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_build_vocab\n",
      "_build_model\n",
      "(1, 3, 32, 320)\n",
      "(1, 256, 2, 20)\n",
      "backbone feature scale:16\n",
      "speed:0.018733683824539184\n",
      "_build_dataloader\n",
      "该数据集的图像经过cnn后会沿水平抽取出8个特征向量，请确保每个字符的宽度大于图像宽度/8，否则信息可能丢失，需调大char_embed_ratio\n",
      "该数据集的图像经过cnn后会沿水平抽取出8个特征向量，请确保每个字符的宽度大于图像宽度/8，否则信息可能丢失，需调大char_embed_ratio\n",
      "(32, 128, 3)\n",
      "[41, 57, 49, 55, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# backbone_choices={\"MobileNetV2_small\":MobileNetV2_small,\n",
    "#                   \"MobileNetV2_mid\":MobileNetV2_mid,\n",
    "#                   \"MobileNetV2_large\":MobileNetV2_large,\n",
    "#                   \"ResNetV2_small\":ResNetV2_small,\n",
    "#                   \"ResNetV2_mid\":ResNetV2_mid,\n",
    "#                   \"ResNetV2_large\":ResNetV2_large,\n",
    "#                   \"DenseNet\":DenseNet}\n",
    "def Do_train():\n",
    "    Train_tool = crnn_trainer(train_root='../金融许可train',\n",
    "                          test_root='../金融许可test',lstm_hid=64,backbone='ResNetV2_mid',model_dir='model_mvsmall',\n",
    "                          concat_num=1,batch_size = 32,s_lr=0.01,e_lr=0.0001)#,pretrained='/data3/ml/fansen/.mxnet/models/mobilenetv2_0.25-9b1d2cc3.params')#pretrained='demo.params',s_lr=0.0001,e_lr=0.00001\n",
    "#     Train_tool.do_training()\n",
    "    Train_tool.check_train_iter()\n",
    "Do_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0,
     21,
     32
    ]
   },
   "outputs": [],
   "source": [
    "class crnn_api(object):\n",
    "    \n",
    "    def __init__(self,model_dir,ctx):\n",
    "        self.ctx=ctx\n",
    "        files = [os.path.join(model_dir,i) for i in os.listdir(model_dir)]\n",
    "        info_json=[i for i in files if 'json' in i][0]\n",
    "        self.weight = [i for i in files if 'param' in i][0]\n",
    "        self._restore(info_json)\n",
    "\n",
    "        \n",
    "    def _restore(self,jsonf):\n",
    "        with open(jsonf, 'r') as f:\n",
    "            self.info = json.load(f)\n",
    "            \n",
    "        self.idx2vocab=self.info['idx2vocab']\n",
    "        CRNN=backbone_choices[self.info['backbone']]\n",
    "        self.input_size=tuple(self.info['input_size'])\n",
    "        self.cls_num=self.info['cls_num']\n",
    "        self.crnn = CRNN(classes=self.cls_num+1,lstm_hid=self.info['lstm_hid'])\n",
    "        self.crnn.load_parameters(self.weight, ctx=self.ctx)\n",
    "        \n",
    "    def _ctc_label(self,p):\n",
    "        ret = []\n",
    "        p1 = [self.cls_num] + p\n",
    "        for i in range(len(p)):\n",
    "            c1 = p1[i]\n",
    "            c2 = p1[i + 1]\n",
    "            if c2 == self.cls_num or c2 == c1:\n",
    "                continue\n",
    "            ret.append(c2)\n",
    "        return ret\n",
    "    \n",
    "    def preprocess(self,img):\n",
    "        img=cv2.resize(img,self.input_size)\n",
    "        new_img = np.multiply(img, 1 / 255.0)\n",
    "        new_img = new_img.transpose(2, 0, 1)\n",
    "        in_put = nd.array([new_img],ctx=self.ctx)\n",
    "        return in_put\n",
    "\n",
    "    def post_process(self,pre_distribution):\n",
    "        cls = nd.argmax(pre_distribution, axis=2).asnumpy().tolist()  \n",
    "        Pred=self._ctc_label(cls[0])\n",
    "        words = []\n",
    "        for w in Pred:\n",
    "            words.append(self.idx2vocab[str(int(w))])\n",
    "\n",
    "        return(''.join(words))\n",
    "    \n",
    "    def predict(self, img):\n",
    "        in_put = self.preprocess(img)\n",
    "        pre_distribution = self.crnn(in_put)\n",
    "        result = self.post_process(pre_distribution)\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer =crnn_api(\"model_mvsmall\",ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28yP\n",
      "0.03558945655822754\n"
     ]
    }
   ],
   "source": [
    "npimg = cv2.imread('28yP.jpg')\n",
    "A=time.time()\n",
    "print(infer.predict(npimg))\n",
    "B=time.time()\n",
    "print(B-A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
